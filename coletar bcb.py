import requests
import pandas as pd
import time
import os
from datetime import datetime

def create_directories():
    """Cria os diret√≥rios necess√°rios para salvar os dados"""
    os.makedirs('data/raw/bcb', exist_ok=True)
    os.makedirs('data/processed', exist_ok=True)

def get_bcb_series_with_retry():
    """
    Coleta s√©ries do Banco Central Brasil (2018-2024) com retry para timeouts
    """
    print("Coletando dados do Banco Central...")
    
    # C√≥digos das s√©ries do SGS
    series_bcb = {
        'ipca': 433,                    # IPCA
        'ipca_acumulado_12m': 13522,    # IPCA acumulado 12 meses
        'divida_total_familias': 4390,  # D√≠vida total das fam√≠lias (% renda)
        'credito_total': 20714,         # Cr√©dito total
        'credito_pessoal': 20716,       # Cr√©dito pessoal
        'taxa_juros_pessoal': 20796,    # Taxa de juros - pessoal
        'inadimplencia': 21082,         # Taxa de inadimpl√™ncia
        'poupanca': 196,                # Poupan√ßa
    }
    
    bcb_data = {}
    failed_series = []
    
    for name, code in series_bcb.items():
        print(f"Coletando s√©rie BCB: {name} ({code})")
        
        max_retries = 3
        for attempt in range(max_retries):
            try:
                # API do BCB
                url = f"https://api.bcb.gov.br/dados/serie/bcdata.sgs.{code}/dados"
                params = {
                    'formato': 'json',
                    'dataInicial': '01/01/2018',
                    'dataFinal': '31/12/2024'
                }
                
                # Timeout menor para tentativas iniciais, maior para as seguintes
                timeout = 15 if attempt == 0 else 30
                response = requests.get(url, params=params, timeout=timeout)
                
                if response.status_code == 200:
                    data = response.json()
                    
                    if data:
                        df = pd.DataFrame(data)
                        df['data'] = pd.to_datetime(df['data'], dayfirst=True)
                        df['valor'] = pd.to_numeric(df['valor'], errors='coerce')
                        
                        # Ordenar por data
                        df = df.sort_values('data')
                        
                        bcb_data[name] = df
                        df.to_csv(f'data/raw/bcb/{name}_2018_2024.csv', index=False)
                        print(f"‚úì {name}: {len(df)} registros (de {df['data'].min().strftime('%Y-%m')} a {df['data'].max().strftime('%Y-%m')})")
                        break  # Sai do loop de retry se bem-sucedido
                    else:
                        print(f"‚úó {name}: Dados vazios")
                        break
                else:
                    print(f"‚úó {name}: HTTP {response.status_code} (tentativa {attempt + 1}/{max_retries})")
                    if attempt == max_retries - 1:
                        failed_series.append(name)
            
            except requests.exceptions.Timeout:
                print(f"‚úó Timeout na s√©rie {name} (tentativa {attempt + 1}/{max_retries})")
                if attempt == max_retries - 1:
                    failed_series.append(name)
                    print(f"  ‚ö†Ô∏è S√©rie {name} falhou ap√≥s {max_retries} tentativas")
            
            except Exception as e:
                print(f"‚úó Erro na s√©rie {name}: {e} (tentativa {attempt + 1}/{max_retries})")
                if attempt == max_retries - 1:
                    failed_series.append(name)
            
            # Aguarda antes da pr√≥xima tentativa (backoff exponencial)
            if attempt < max_retries - 1:
                wait_time = 2 ** attempt  # 1, 2, 4 segundos
                print(f"  Aguardando {wait_time}s antes da pr√≥xima tentativa...")
                time.sleep(wait_time)
            else:
                time.sleep(1)  # Aguarda 1s entre s√©ries diferentes
    
    if failed_series:
        print(f"\n‚ö†Ô∏è S√©ries que falharam: {', '.join(failed_series)}")
    
    return bcb_data

def calculate_inflation_impact():
    """
    Calcula impacto da infla√ß√£o no poder de compra
    """
    try:
        # Carregar IPCA
        ipca_df = pd.read_csv('data/raw/bcb/ipca_2018_2024.csv')
        ipca_df['data'] = pd.to_datetime(ipca_df['data'])
        
        # Ordenar por data
        ipca_df = ipca_df.sort_values('data')
        
        # Calcular IPCA acumulado
        ipca_df['ipca_acumulado'] = (1 + ipca_df['valor']/100).cumprod() - 1
        ipca_df['perda_poder_compra'] = 1 - (1 / (1 + ipca_df['ipca_acumulado']))
        
        # Calcular perda percentual
        ipca_df['perda_poder_compra_pct'] = ipca_df['perda_poder_compra'] * 100
        
        # Salvar an√°lise
        ipca_df.to_csv('data/processed/impacto_inflacao.csv', index=False)
        
        # Estat√≠sticas resumidas
        ultimo_mes = ipca_df.iloc[-1]
        print(f"‚úì An√°lise de impacto da infla√ß√£o calculada")
        print(f"  Perda acumulada do poder de compra: {ultimo_mes['perda_poder_compra_pct']:.2f}%")
        print(f"  IPCA acumulado no per√≠odo: {ultimo_mes['ipca_acumulado']*100:.2f}%")
        
        return ipca_df
        
    except Exception as e:
        print(f"Erro no c√°lculo do impacto da infla√ß√£o: {e}")
        return None

def analyze_debt_credit_data():
    """
    An√°lise integrada de d√≠vida e cr√©dito (robusta a dados faltantes)
    """
    try:
        # Lista de arquivos dispon√≠veis
        available_files = []
        required_files = [
            'divida_total_familias_2018_2024.csv',
            'credito_total_2018_2024.csv', 
            'inadimplencia_2018_2024.csv'
        ]
        
        for file in required_files:
            if os.path.exists(f'data/raw/bcb/{file}'):
                available_files.append(file)
            else:
                print(f"‚ö†Ô∏è Arquivo n√£o encontrado: {file}")
        
        if len(available_files) < 2:
            print("‚ùå Dados insuficientes para an√°lise de d√≠vida e cr√©dito")
            return None
        
        # Carregar dados dispon√≠veis
        data_frames = {}
        for file in available_files:
            series_name = file.replace('_2018_2024.csv', '')
            df = pd.read_csv(f'data/raw/bcb/{file}')
            df['data'] = pd.to_datetime(df['data'])
            data_frames[series_name] = df
        
        # Come√ßar com o primeiro dataframe
        analise_df = list(data_frames.values())[0].copy()
        current_name = list(data_frames.keys())[0]
        
        # Juntar todos os dados dispon√≠veis
        for name, df in list(data_frames.items())[1:]:
            analise_df = analise_df.merge(df, on='data', how='outer', suffixes=('', f'_{name}'))
        
        # Renomear colunas para ficarem claras
        column_mapping = {
            'valor': current_name,
            'valor_divida_total_familias': 'divida_familias_pct',
            'valor_credito_total': 'credito_total', 
            'valor_inadimplencia': 'inadimplencia',
            'valor_taxa_juros_pessoal': 'taxa_juros'
        }
        
        analise_df = analise_df.rename(columns=column_mapping)
        
        # Manter apenas colunas relevantes
        keep_cols = ['data'] + [col for col in analise_df.columns if col.startswith(('divida', 'credito', 'inadimplencia', 'taxa_juros'))]
        analise_df = analise_df[keep_cols]
        
        # Ordenar por data
        analise_df = analise_df.sort_values('data')
        
        # Salvar an√°lise consolidada
        analise_df.to_csv('data/processed/analise_divida_credito.csv', index=False)
        print(f"‚úì An√°lise de d√≠vida e cr√©dito consolidada ({len(available_files)} s√©ries)")
        
        # Estat√≠sticas b√°sicas
        print(f"  Per√≠odo: {analise_df['data'].min().strftime('%Y-%m')} a {analise_df['data'].max().strftime('%Y-%m')}")
        print(f"  S√©ries inclu√≠das: {', '.join(available_files)}")
        
        return analise_df
        
    except Exception as e:
        print(f"Erro na an√°lise de d√≠vida e cr√©dito: {e}")
        return None

def generate_summary_report():
    """
    Gera um relat√≥rio resumido dos dados coletados
    """
    print("\n" + "="*50)
    print("RELAT√ìRIO RESUMO - DADOS BCB 2018-2024")
    print("="*50)
    
    # Verificar arquivos coletados
    raw_files = os.listdir('data/raw/bcb')
    processed_files = os.listdir('data/processed')
    
    print(f"\nüìä Arquivos coletados: {len(raw_files)}")
    for file in sorted(raw_files):
        file_path = f'data/raw/bcb/{file}'
        df = pd.read_csv(file_path)
        dates = pd.to_datetime(df['data'])
        print(f"   ‚Ä¢ {file.replace('_2018_2024.csv', '')}: {len(df)} registros ({dates.min().strftime('%Y-%m')} a {dates.max().strftime('%Y-%m')})")
    
    print(f"\nüìà An√°lises processadas: {len(processed_files)}")
    for file in sorted(processed_files):
        print(f"   ‚Ä¢ {file}")
    
    # Estat√≠stica principal da infla√ß√£o
    if os.path.exists('data/processed/impacto_inflacao.csv'):
        inflacao_df = pd.read_csv('data/processed/impacto_inflacao.csv')
        ultimo_mes = inflacao_df.iloc[-1]
        print(f"\nüí∞ Impacto da Infla√ß√£o (2018-2024):")
        print(f"   ‚Ä¢ IPCA Acumulado: {ultimo_mes['ipca_acumulado']*100:.2f}%")
        print(f"   ‚Ä¢ Perda do Poder de Compra: {ultimo_mes['perda_poder_compra_pct']:.2f}%")

# Executar coleta
if __name__ == "__main__":
    # Criar diret√≥rios
    create_directories()
    
    # Coletar dados com retry
    bcb_data = get_bcb_series_with_retry()
    
    # Calcular an√°lises
    inflation_impact = calculate_inflation_impact()
    debt_analysis = analyze_debt_credit_data()
    
    # Gerar relat√≥rio
    generate_summary_report()
    
    print("\n‚úÖ Processamento conclu√≠do!")